{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_upCOEI3Upu"
      },
      "source": [
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит предсказывать год выпуска песни (**задача регрессии**) по некоторым звуковым признакам: [данные](https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd). В ячейках ниже находится код для загрузки данных. Обратите внимание, что обучающая и тестовая выборки располагаются в одном файле, поэтому НЕ меняйте ячейку, в которой производится деление данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI_eoe063VaP"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchmetrics.regression import MeanSquaredError\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import tqdm\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NgSZeU-7vgj"
      },
      "outputs": [],
      "source": [
        "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSVJZzkJ7zZE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.txt.zip\", header=None)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdO0CY0rvYiH"
      },
      "outputs": [],
      "source": [
        "df.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "n4wnRJT1778j"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "train_size = 463715\n",
        "X_train = X[:train_size, :]\n",
        "y_train = y[:train_size]\n",
        "X_test = X[train_size:, :]\n",
        "y_test = y[train_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_386JE_o5gOd"
      },
      "source": [
        "## Задание 0. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
        "\n",
        "Мы будем использовать RMSE как метрику качества. Для самого первого бейзлайна обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otwuisa56MLr",
        "outputId": "8ae0a66c-7439-4dd8-963f-83edb24f085c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 9.510160711373397\n",
            "RMSE constant: 10.85246390513634\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#обучим\n",
        "model = Ridge(alpha=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#считаем качество\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "#наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток по trainу\n",
        "constant_pred = [y_train.mean()] * len(y_test)\n",
        "rmse_constant = mean_squared_error(y_test, constant_pred, squared=False)\n",
        "print(f'RMSE constant: {rmse_constant}')\n",
        "\n",
        "#при константном прогнозе хуже"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ilBKYt6OdD"
      },
      "source": [
        "## Задание 1. (максимум 10 баллов)\n",
        "\n",
        "Реализуйте обучение и тестирование нейронной сети для предоставленного вам набора данных. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
        "\n",
        "- $\\text{RMSE} \\le 9.00 $ &mdash; 4 балла\n",
        "- $\\text{RMSE} \\le 8.90 $ &mdash; 6 баллов\n",
        "- $\\text{RMSE} \\le 8.80 $ &mdash; 8 баллов\n",
        "- $\\text{RMSE} \\le 8.75 $ &mdash; 10 баллов\n",
        "\n",
        "Есть несколько правил, которых вам нужно придерживаться:\n",
        "\n",
        "- Весь пайплайн обучения должен быть написан на PyTorch. При этом вы можете пользоваться другими библиотеками (`numpy`, `sklearn` и пр.), но только для обработки данных. То есть как угодно трансформировать данные и считать метрики с помощью этих библиотек можно, а импортировать модели из `sklearn` и выбивать с их помощью требуемое качество &mdash; нельзя. Также нельзя пользоваться библиотеками, для которых сам PyTorch является зависимостью.\n",
        "\n",
        "- Мы никак не ограничиваем ваш выбор архитектуры модели, но скорее всего вам будет достаточно полносвязной нейронной сети.\n",
        "\n",
        "- Для обучения запрещается использовать какие-либо иные данные, кроме обучающей выборки.\n",
        "\n",
        "- Ансамблирование моделей запрещено.\n",
        "\n",
        "### Полезные советы:\n",
        "\n",
        "- Очень вряд ли, что у вас с первого раза получится выбить качество на 10 баллов, поэтому пробуйте разные архитектуры, оптимизаторы и значения гиперпараметров. В идеале при запуске каждого нового эксперимента вы должны менять что-то одно, чтобы точно знать, как этот фактор влияет на качество.\n",
        "\n",
        "- Не забудьте, что для улучшения качества модели вам поможет **нормировка таргета**.\n",
        "\n",
        "- Тот факт, что мы занимаемся глубинным обучением, не означает, что стоит забывать про приемы, использующиеся в классическом машинном обучении. Так что обязательно проводите исследовательский анализ данных, отрисовывайте нужные графики и не забывайте про масштабирование и подбор гиперпараметров.\n",
        "\n",
        "- Вы наверняка столкнетесь с тем, что ваша нейронная сеть будет сильно переобучаться. Для нейросетей существуют специальные методы регуляризации, например, dropout ([статья](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)) и weight decay ([блогпост](https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd)). Они, разумеется, реализованы в PyTorch. Попробуйте поэкспериментировать с ними.\n",
        "\n",
        "- Если вы чего-то не знаете, не гнушайтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению в целом и по PyTorch в частности. Но не забывайте, что за скатанный код без ссылки на источник придется ответить по всей строгости!\n",
        "\n",
        "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
        "\n",
        "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так!\n",
        "\n",
        "- Пользуйтесь утилитами, которые вам предоставляет PyTorch (например, Dataset и Dataloader). Их специально разработали для упрощения разработки пайплайна обучения.\n",
        "\n",
        "- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
        "\n",
        "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
        "\n",
        "**ОБЯЗАТЕЛЬНО** рисуйте графики зависимости лосса/метрики на обучающей и тестовой выборках в зависимости от времени обучения. Если обучение занимает относительно небольшое число эпох, то лучше рисовать зависимость от номера шага обучения, если же эпох больше, то рисуйте зависимость по эпохам. Если проверяющий не увидит такого графика для вашей лучшей модели, то он в праве снизить баллы за задание.\n",
        "\n",
        "**ВАЖНО!** Ваше решение должно быть воспроизводимым. Если это не так, то проверяющий имеет право снизить баллы за задание. Чтобы зафиксировать random seed, воспользуйтесь функцией из ячейки ниже.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VaMButDmEKKw"
      },
      "outputs": [],
      "source": [
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "71lX5nuNeN7L"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yUzAgRkVK3k2"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "def create_data_loader(X_train, y_train, X_test, y_test):\n",
        "    train_tensor = torch.utils.data.TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train))\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_tensor, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_tensor = torch.utils.data.TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test))\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_tensor, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "#модель 1\n",
        "class TorchModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=INPUT_SIZE, out_features=HIDDEN_SIZE1)\n",
        "        self.fc2 = nn.Linear(in_features=HIDDEN_SIZE1, out_features=HIDDEN_SIZE2)\n",
        "        self.out = nn.Linear(in_features=HIDDEN_SIZE2, out_features=OUTPUT_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = nn.LeakyReLU()(self.fc1(x))\n",
        "        x = nn.LeakyReLU()(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "# модель 2\n",
        "def build_model():\n",
        "    model = nn.Sequential(\n",
        "\n",
        "        nn.Linear(in_features=INPUT_SIZE, out_features=HIDDEN_SIZE1),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(in_features=HIDDEN_SIZE1, out_features=HIDDEN_SIZE2),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(in_features=HIDDEN_SIZE2, out_features=OUTPUT_SIZE),\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# разница моделей только в функциях активаций"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZW0gMe3vT8u"
      },
      "source": [
        "Вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться следующими сигнатурами функций. Лучше всего, если вы проверите ваши предсказания ассертом: так вы убережете себя от разных косяков, например, что вектор предсказаний состоит из всего одного числа. В любом случае, внимательно следите за тем, для каких тензоров вы считаете метрику RMSE. При случайном или намеренном введении в заблуждение проверяющие очень сильно разозлятся."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "iB-eeJY1uAN5"
      },
      "outputs": [],
      "source": [
        "# определяем параметры, model, optimizer, criterion, mse, train_loader, test_loader\n",
        "INPUT_SIZE = 90 # количество признаков\n",
        "HIDDEN_SIZE1 = 50 # просто так\n",
        "HIDDEN_SIZE2 = 50\n",
        "OUTPUT_SIZE = 1 # ну регрессия..\n",
        "LEARNING_RATE = 0.001 # просто так\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# model = TorchModel()\n",
        "model = build_model()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, nesterov=True)\n",
        "criterion = nn.MSELoss()\n",
        "train_loader, test_loader = create_data_loader(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wmxrf5Qveux",
        "outputId": "3b75c704-50e4-4be7-cc63-ca65dfc90f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 86.82891845703125\n",
            "Epoch: 2, loss: 91.89496612548828\n",
            "Epoch: 4, loss: 82.7640609741211\n",
            "Epoch: 6, loss: 50.09684371948242\n",
            "Epoch: 8, loss: 69.33561706542969\n",
            "Epoch: 10, loss: 66.44021606445312\n",
            "Epoch: 12, loss: 9.089938163757324\n",
            "Epoch: 14, loss: 8.318602561950684\n",
            "Epoch: 16, loss: 8.457962989807129\n",
            "Epoch: 18, loss: 8.234057426452637\n",
            "Epoch: 20, loss: 8.228263854980469\n",
            "Epoch: 22, loss: 8.18273639678955\n",
            "Epoch: 24, loss: 8.329277992248535\n",
            "Epoch: 26, loss: 8.460043907165527\n",
            "Epoch: 28, loss: 8.27056884765625\n",
            "Epoch: 30, loss: 8.471128463745117\n",
            "Epoch: 32, loss: 8.570989608764648\n",
            "Epoch: 34, loss: 8.34836483001709\n",
            "Epoch: 36, loss: 8.439382553100586\n",
            "Epoch: 38, loss: 8.274364471435547\n",
            "Epoch: 40, loss: 8.638384819030762\n",
            "Epoch: 42, loss: 8.214567184448242\n",
            "Epoch: 44, loss: 8.294500350952148\n",
            "Epoch: 46, loss: 8.251840591430664\n",
            "Epoch: 48, loss: 8.694552421569824\n",
            "Epoch: 50, loss: 8.293304443359375\n",
            "Epoch: 52, loss: 9.085431098937988\n",
            "Epoch: 54, loss: 8.320042610168457\n",
            "Epoch: 56, loss: 8.349442481994629\n",
            "Epoch: 58, loss: 8.50931453704834\n",
            "Epoch: 60, loss: 8.506498336791992\n",
            "Epoch: 62, loss: 8.342798233032227\n",
            "Epoch: 64, loss: 8.519107818603516\n",
            "Epoch: 66, loss: 8.293534278869629\n",
            "Epoch: 68, loss: 8.533509254455566\n",
            "Epoch: 70, loss: 8.280147552490234\n",
            "Epoch: 72, loss: 8.420910835266113\n",
            "Epoch: 74, loss: 8.531734466552734\n",
            "Epoch: 76, loss: 8.346088409423828\n",
            "Epoch: 78, loss: 8.36612606048584\n",
            "Epoch: 80, loss: 8.268689155578613\n",
            "Epoch: 82, loss: 8.324270248413086\n",
            "Epoch: 84, loss: 8.396613121032715\n",
            "Epoch: 86, loss: 8.315115928649902\n",
            "Epoch: 88, loss: 8.466991424560547\n",
            "Epoch: 90, loss: 8.331463813781738\n",
            "Epoch: 92, loss: 8.320486068725586\n",
            "Epoch: 94, loss: 8.787971496582031\n",
            "Epoch: 96, loss: 8.288488388061523\n",
            "Epoch: 98, loss: 8.831460952758789\n"
          ]
        }
      ],
      "source": [
        "def train_eval(model, optimizer, criterion, train_loader, test_loader):\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        # тренировка\n",
        "        model.train()\n",
        "        for x_train, y_train in train_loader:\n",
        "            y_pred = model(x_train).squeeze()\n",
        "            loss = torch.sqrt(criterion(y_pred, y_train.float()))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # валидация\n",
        "        model.eval()\n",
        "        val_loss = []\n",
        "        if epoch % 2 == 0:\n",
        "            with torch.no_grad():\n",
        "                for x_test, y_test in test_loader:\n",
        "                    y_pred = model(x_test).squeeze()\n",
        "                    loss = torch.sqrt(criterion(y_pred, y_test))\n",
        "                    val_loss.append(loss.numpy())\n",
        "            # печатаем метрики\n",
        "            print(f\"Epoch: {epoch}, loss: {np.mean(val_loss)}\")\n",
        "\n",
        "train_eval(model, optimizer, criterion, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yxmAZqhnbD2"
      },
      "source": [
        "я не плачу, это просто слезы...\n",
        "\n",
        "можно остановить на эпохе с 14 по 92, кроме 52 - там все результаты стабильно хорошие, а на 98 предлагаю не смотреть..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bine9EES6TIn"
      },
      "source": [
        "## Задание 2. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
        "\n",
        "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTOdBR17cDZ9"
      },
      "source": [
        "ОТЧЕТ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXBK02qVW4Vs"
      },
      "source": [
        "**БЕЙЗЛАЙН**\n",
        "модель без всяких приколов, без методов регуляризации и нормировки таргета\n",
        "с 14-й эпохи лосс застревает на 12-ти и ни туда, ни сюда\n",
        "\n",
        "модель - 3 полносвязных слоя, 2 функции активации(ReLU)\n",
        "\n",
        "оптимизатор - Адам\n",
        "\n",
        "метрика - MSELoss, из которого я беру корень, чтобы получить RMSE\n",
        "\n",
        "Epoch: 0, loss: 139.52838134765625\n",
        "\n",
        "Epoch: 2, loss: 140.1300048828125\n",
        "\n",
        "Epoch: 4, loss: 113.22109985351562\n",
        "\n",
        "Epoch: 6, loss: 108.7522201538086\n",
        "\n",
        "Epoch: 8, loss: 93.57054138183594\n",
        "\n",
        "Epoch: 10, loss: 53.852272033691406\n",
        "\n",
        "Epoch: 12, loss: 10.68622875213623\n",
        "\n",
        "Epoch: 14, loss: 12.874173164367676\n",
        "\n",
        "Epoch: 16, loss: 12.602913856506348\n",
        "\n",
        "Epoch: 18, loss: 12.697125434875488\n",
        "\n",
        "Epoch: 20, loss: 12.653617858886719\n",
        "\n",
        "Epoch: 22, loss: 12.87939167022705\n",
        "\n",
        "и т.д."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFLbhQCdcBzn"
      },
      "source": [
        "**что мы можем сделать дальше:**\n",
        "1. попробовать разные оптимизаторы (на паре мы разобрали SGD, SGD с Nesterov Momentum, RMSprop, Adam - можно начать с этого)\n",
        "2. стратегии с постепенным понижением lr\n",
        "3. методы регуляризации, например, dropout и weight decay\n",
        "4. нормировка таргета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCPW1n5ufpIu"
      },
      "source": [
        "**начала с нормировки таргета**(скопипастила код из тетрадки для StandardScaler)\n",
        "\n",
        "что получилось:\n",
        "\n",
        "Epoch: 0, loss: 21.49457359313965\n",
        "\n",
        "Epoch: 2, loss: 15.128954887390137\n",
        "\n",
        "Epoch: 4, loss: 16.115442276000977\n",
        "\n",
        "Epoch: 6, loss: 22.802265167236328\n",
        "\n",
        "Epoch: 8, loss: 11.895721435546875\n",
        "\n",
        "Epoch: 10, loss: 22.3963565826416\n",
        "\n",
        "Epoch: 12, loss: 12.845952033996582\n",
        "\n",
        "Epoch: 14, loss: 10.230569839477539\n",
        "\n",
        "Epoch: 16, loss: 13.71241569519043\n",
        "\n",
        "Epoch: 18, loss: 13.096126556396484\n",
        "\n",
        "Epoch: 20, loss: 13.875551223754883\n",
        "\n",
        "Epoch: 22, loss: 18.023155212402344\n",
        "\n",
        "Epoch: 24, loss: 12.96262264251709\n",
        "\n",
        "лосс скачет - такое не нравится,\n",
        "но как будто нормализовать надо, так что оставлю (хуже не стало)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EprizALOgl4f"
      },
      "source": [
        "**попробуем другой оптимизатор**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_aerE4EgpFa"
      },
      "source": [
        "начнем с SGD:\n",
        "\n",
        "стало хуже, надежда покидает эту тетрадку\n",
        "\n",
        "Epoch: 0, loss: 64.96495819091797\n",
        "\n",
        "Epoch: 2, loss: 38.51618576049805\n",
        "\n",
        "Epoch: 4, loss: 49.212833404541016\n",
        "\n",
        "Epoch: 6, loss: 54.370906829833984\n",
        "\n",
        "Epoch: 8, loss: 43.79151916503906\n",
        "\n",
        "Epoch: 10, loss: 43.910736083984375\n",
        "\n",
        "Epoch: 12, loss: 41.21782684326172\n",
        "\n",
        "Epoch: 14, loss: 45.677703857421875"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWEzvtfvl7Xn"
      },
      "source": [
        "**SGD с Nesterov Momentum**\n",
        "\n",
        "пока из всего, что было - **лучший результат**, но это настораживает, модель вроде простая, странно, что так хорошо...\n",
        "\n",
        "\n",
        "**на 22-й эпохе результат 8.18**.............\n",
        "\n",
        "\n",
        "параметры, которые показали лучший результат:\n",
        "\n",
        "```\n",
        "INPUT_SIZE = 90 # количество признаков\n",
        "HIDDEN_SIZE = 50 # просто так\n",
        "HIDDEN_SIZE = \n",
        "OUTPUT_SIZE = 1 # ну регрессия..\n",
        "LEARNING_RATE = 0.001 # просто так\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "model = build_model() # тут все очень обычно, архитектуру не меняла\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, nesterov=True)\n",
        "criterion = nn.MSELoss()\n",
        "train_loader, test_loader = create_data_loader(X_train, y_train, X_test, y_test)\n",
        "```\n",
        "\n",
        "\n",
        "ИТОГО:\n",
        "я попробовала 3 разных оптимизатора (ADAM, SGD и SGD с Nesterov Momentum), добавила нормировку таргета и поменяла у модели функцию активации с LeakyRelu на Relu (последнее, думаю, не сильно повлияло), где то между этим меняла HIDDEN_SIZE, но 50 на двух слоях оказалось нормально (в самом начале )\n",
        "\n",
        "больше всего повлиял выбор оптимизатора\n",
        "\n",
        "не уверена, что стоит менять HIDDEN_SIZE, можно попробовать стратегию с понижением LEARNING_RATE, но уже и так все хорошо работает!!\n",
        "\n",
        "копипастила из тетрадок структуру моделей, даталоадер, функцию для test_eval, но (естественно) меняла параметры, функции активации и т.д.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "P.S. прогнала всю тетрадку еще раз (на всякий случай) и мне поплохело, когда увидела, что лосс растет, но после 10-й эпохи все стало норм\n",
        "\n",
        "Epoch: 0, loss: 50.518192291259766\n",
        "\n",
        "Epoch: 2, loss: 88.33194732666016\n",
        "\n",
        "Epoch: 4, loss: 96.55126190185547\n",
        "\n",
        "Epoch: 6, loss: 103.18949127197266\n",
        "\n",
        "Epoch: 8, loss: 64.23108673095703\n",
        "\n",
        "Epoch: 10, loss: 74.18192291259766\n",
        "\n",
        "Epoch: 12, loss: 8.650042533874512\n",
        "\n",
        "Epoch: 14, loss: 8.221396446228027\n",
        "\n",
        "Epoch: 16, loss: 8.801286697387695\n",
        "\n",
        "Epoch: 18, loss: 8.362936973571777\n",
        "\n",
        "Epoch: 20, loss: 8.606343269348145\n",
        "\n",
        "Epoch: 22, loss: 8.195330619812012"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
